# 小说训练数据生成器

这是一个基于Gradio的Web应用，用于将小说文本转换为RWKV模型指令微调格式的训练数据。

## 功能特点

- 📚 支持上传整本小说文件（.txt, .md格式）
- 🧹 自动清理文本，去除空行和标题
- ✂️ 智能分割段落，可调节段落长度
- 🔤 自动提取关键词作为指令
- 📝 生成标准的指令微调格式（Instruction-Input-Response）
- 💾 支持导出JSONL格式训练数据

## 安装依赖

```bash
pip install -r requirements.txt
```

## 运行程序

```bash
python novel_processor.py
```

程序启动后会在浏览器中打开Web界面，默认地址：http://localhost:7860

## 使用方法

1. **上传小说文件**：点击"上传小说文件"按钮，选择.txt或.md格式的小说文件

2. **调整参数**：
   - 最小段落长度：控制每个训练样本的最小字符数
   - 最大段落长度：控制每个训练样本的最大字符数

3. **处理文件**：点击"处理文件"按钮开始生成训练数据

4. **查看结果**：在右侧文本框中查看生成的JSONL格式数据

5. **保存文件**：输入文件名并点击"保存文件"按钮将数据保存到本地

## 数据格式说明

生成的训练数据采用以下格式：

```json
{
  "text": "Instruction: 请根据关键词'武功、内力、修炼'续写小说段落\n\nInput: 张三在山洞中发现了一本古老的武功秘籍...\n\nResponse: 他小心翼翼地翻开秘籍，只见上面记载着一门名为'九阳神功'的绝世武学..."
}
```

### 格式组成

- **Instruction**: 包含从后续段落提取的关键词，指导模型续写方向
- **Input**: 前一段小说内容，作为续写的上下文
- **Response**: 后一段小说内容，作为期望的输出结果

## 技术特性

- **智能分词**：使用jieba分词库进行中文文本处理
- **关键词提取**：基于词频统计自动提取段落关键词
- **文本清理**：自动去除章节标题、多余空行等格式内容
- **段落分割**：基于句号、问号、感叹号进行智能段落划分
- **响应式界面**：基于Gradio构建的现代化Web界面

## 注意事项

- 建议上传的小说文件大小不超过10MB
- 段落长度设置会影响训练数据的质量，建议根据具体需求调整
- 生成的数据量取决于原文长度和段落分割设置
- 支持中文小说处理，对其他语言的支持可能有限

## 许可证

本项目采用MIT许可证，详见LICENSE文件。